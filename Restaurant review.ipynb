{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessory documents.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout,Bidirectional,Embedding\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_excel('../dataset/Restaurant_Reviews.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Review', 'Liked'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words Vocabulary, we can make it 10,000 to imporove the words representation.\n",
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = df['Review']\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2197, 2710, 3595, 192]\n",
      "Wow... Loved this place.\n"
     ]
    }
   ],
   "source": [
    "print(onehot_repr[0])\n",
    "print(messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length=20 #\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0, 2197, 2710, 3595,  192]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 50)            250000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 310,501\n",
      "Trainable params: 310,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "embedding_vector_features=50\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(df['Liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6924 - acc: 0.5412 - val_loss: 0.6914 - val_acc: 0.5700\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 1s 646us/sample - loss: 0.6835 - acc: 0.7237 - val_loss: 0.6828 - val_acc: 0.5900\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 598us/sample - loss: 0.6376 - acc: 0.6888 - val_loss: 0.6577 - val_acc: 0.6300\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 1s 650us/sample - loss: 0.5208 - acc: 0.7763 - val_loss: 0.5738 - val_acc: 0.7250\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.3832 - acc: 0.8525 - val_loss: 0.5559 - val_acc: 0.7250\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 1s 792us/sample - loss: 0.2487 - acc: 0.9162 - val_loss: 0.6356 - val_acc: 0.7350\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 537us/sample - loss: 0.1691 - acc: 0.9413 - val_loss: 0.7460 - val_acc: 0.7350\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 568us/sample - loss: 0.1677 - acc: 0.9463 - val_loss: 0.5966 - val_acc: 0.7400\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 532us/sample - loss: 0.1105 - acc: 0.9775 - val_loss: 0.7323 - val_acc: 0.7450\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 585us/sample - loss: 0.0771 - acc: 0.9825 - val_loss: 0.8757 - val_acc: 0.7350\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 578us/sample - loss: 0.0603 - acc: 0.9875 - val_loss: 0.8414 - val_acc: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 563us/sample - loss: 0.0504 - acc: 0.9937 - val_loss: 0.8324 - val_acc: 0.7800\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 1s 823us/sample - loss: 0.0477 - acc: 0.9912 - val_loss: 1.0264 - val_acc: 0.7500\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 1s 758us/sample - loss: 0.0376 - acc: 0.9962 - val_loss: 1.2426 - val_acc: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 1s 716us/sample - loss: 0.0364 - acc: 0.9950 - val_loss: 1.0604 - val_acc: 0.7600\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 1s 640us/sample - loss: 0.0276 - acc: 0.9975 - val_loss: 1.1123 - val_acc: 0.7450\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 611us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 1.1943 - val_acc: 0.7450\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 1.3385 - val_acc: 0.7600\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 542us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.5118 - val_acc: 0.7500\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 526us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.6706 - val_acc: 0.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21399f14808>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finally Training\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics And Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71, 25],\n",
       "       [28, 76]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        96\n",
      "           1       0.75      0.73      0.74       104\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.73      0.74      0.73       200\n",
      "weighted avg       0.74      0.73      0.74       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
