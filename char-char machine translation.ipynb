{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\suresha.bc\\\\Desktop\\\\github files AIML\\\\dataset\\\\fra-eng\\\\fra.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file\n",
    "with open(file_path, 'r', encoding='UTF-8') as f:\n",
    "    lines = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)',\n",
       " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)',\n",
       " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179905"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)# there are 179905 records in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "ephoc = 30\n",
    "num_samples = 6000 # number of samples to train\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_char = set()\n",
    "target_char = set()\n",
    "\n",
    "for line in lines[: 10000]: # I am considering only 10000 samples from 122550 records\n",
    "    input_text , target_text , _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'  # using first word as \\t and End of Sequece as \\n\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    for char in input_text:\n",
    "        if char not in input_char:\n",
    "            input_char.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_char:\n",
    "            target_char.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = sorted(list(input_char))\n",
    "target_chars = sorted(list(target_char))\n",
    "num_encoder_token = len(input_chars)\n",
    "num_decoder_token = len(target_chars)\n",
    "max_encoder_seq_len = max([len(i) for i in input_texts])\n",
    "max_decoder_seq_len = max([len(i) for i in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_token : 71\n",
      "num_decoder_token : 94\n",
      "max_encoder_seq_len : 15\n",
      "max_decoder_seq_len : 59\n"
     ]
    }
   ],
   "source": [
    "print(\"num_encoder_token :\" , num_encoder_token)\n",
    "print(\"num_decoder_token :\" , num_decoder_token)\n",
    "print(\"max_encoder_seq_len :\" , max_encoder_seq_len)\n",
    "print(\"max_decoder_seq_len :\" , max_decoder_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing the tokens\n",
    "input_token_index = dict([(index, char) for char ,index in enumerate(input_chars)])\n",
    "target_token_index = dict([(index, char) for char ,index in enumerate(target_chars)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create encoder & decoder arrays \n",
    "encoder_input_data = np.zeros( (len(input_texts) , max_encoder_seq_len , num_encoder_token ) , dtype='float32' )\n",
    "\n",
    "decoder_input_data = np.zeros( (len(input_texts) , max_decoder_seq_len , num_decoder_token ) , dtype='float32' )\n",
    "\n",
    "decoder_target_data = np.zeros( (len(input_texts) , max_decoder_seq_len , num_decoder_token ) , dtype='float32' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 15, 71), (10000, 59, 94), (10000, 59, 94))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_input_data.shape , decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , (input_text, target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        # one hot representation of input charecters.\n",
    "        encoder_input_data[i,t,input_token_index[char]] = 1. \n",
    "    encoder_input_data[i , t+1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # one hot representation of input charecters.\n",
    "        decoder_input_data[i,t,target_token_index[char]] = 1.\n",
    "          \n",
    "        if t>0:                              \n",
    "            # Decoder target will be ahead of one timestamp (Since we have tab appended)\n",
    "            decoder_target_data[i, t-1, target_token_index[char]] = 1.\n",
    "            \n",
    "    decoder_input_data[i, t+1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t: , target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\suresha.bc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_token))\n",
    "encoder = LSTM(latent_dim,return_state=True)\n",
    "encoder_output , state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None , num_decoder_token))\n",
    "decoder_lstm = LSTM(latent_dim,return_sequences=True , return_state=True )\n",
    "decoder_output , _ ,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_decoder_token, activation='softmax' )\n",
    "decoder_outputs = decoder_dense(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs ,decoder_inputs] , decoder_outputs )\n",
    "model.compile(optimizer='rmsprop' , loss= 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "8000/8000 [==============================] - 127s 16ms/sample - loss: 0.8270 - acc: 0.7763 - val_loss: 0.8237 - val_acc: 0.7644\n",
      "Epoch 2/30\n",
      "8000/8000 [==============================] - 127s 16ms/sample - loss: 0.6706 - acc: 0.8116 - val_loss: 0.6998 - val_acc: 0.7958\n",
      "Epoch 3/30\n",
      "8000/8000 [==============================] - 122s 15ms/sample - loss: 0.5891 - acc: 0.8287 - val_loss: 0.6715 - val_acc: 0.8044\n",
      "Epoch 4/30\n",
      "8000/8000 [==============================] - 122s 15ms/sample - loss: 0.5388 - acc: 0.8425 - val_loss: 0.6160 - val_acc: 0.8174\n",
      "Epoch 5/30\n",
      "8000/8000 [==============================] - 122s 15ms/sample - loss: 0.5006 - acc: 0.8530 - val_loss: 0.5812 - val_acc: 0.8289\n",
      "Epoch 6/30\n",
      "8000/8000 [==============================] - 126s 16ms/sample - loss: 0.4710 - acc: 0.8606 - val_loss: 0.5567 - val_acc: 0.8352\n",
      "Epoch 7/30\n",
      "8000/8000 [==============================] - 127s 16ms/sample - loss: 0.4464 - acc: 0.8677 - val_loss: 0.5416 - val_acc: 0.8400\n",
      "Epoch 8/30\n",
      "8000/8000 [==============================] - 123s 15ms/sample - loss: 0.4250 - acc: 0.8736 - val_loss: 0.5231 - val_acc: 0.8449\n",
      "Epoch 9/30\n",
      "8000/8000 [==============================] - 122s 15ms/sample - loss: 0.4062 - acc: 0.8786 - val_loss: 0.5128 - val_acc: 0.8464\n",
      "Epoch 10/30\n",
      "8000/8000 [==============================] - 120s 15ms/sample - loss: 0.3886 - acc: 0.8836 - val_loss: 0.4971 - val_acc: 0.8530\n",
      "Epoch 11/30\n",
      "8000/8000 [==============================] - 124s 16ms/sample - loss: 0.3730 - acc: 0.8883 - val_loss: 0.4850 - val_acc: 0.8557\n",
      "Epoch 12/30\n",
      "8000/8000 [==============================] - 126s 16ms/sample - loss: 0.3582 - acc: 0.8928 - val_loss: 0.4847 - val_acc: 0.8560\n",
      "Epoch 13/30\n",
      "8000/8000 [==============================] - 124s 16ms/sample - loss: 0.3449 - acc: 0.8963 - val_loss: 0.4723 - val_acc: 0.8596\n",
      "Epoch 14/30\n",
      "8000/8000 [==============================] - 94s 12ms/sample - loss: 0.3321 - acc: 0.9000 - val_loss: 0.4674 - val_acc: 0.8606\n",
      "Epoch 15/30\n",
      "8000/8000 [==============================] - 80s 10ms/sample - loss: 0.3201 - acc: 0.9036 - val_loss: 0.4632 - val_acc: 0.8621\n",
      "Epoch 16/30\n",
      "8000/8000 [==============================] - 79s 10ms/sample - loss: 0.3094 - acc: 0.9065 - val_loss: 0.4591 - val_acc: 0.8650\n",
      "Epoch 17/30\n",
      "8000/8000 [==============================] - 78s 10ms/sample - loss: 0.2978 - acc: 0.9099 - val_loss: 0.4574 - val_acc: 0.8654\n",
      "Epoch 18/30\n",
      "8000/8000 [==============================] - 76s 10ms/sample - loss: 0.2878 - acc: 0.9129 - val_loss: 0.4549 - val_acc: 0.8672\n",
      "Epoch 19/30\n",
      "8000/8000 [==============================] - 76s 10ms/sample - loss: 0.2776 - acc: 0.9160 - val_loss: 0.4501 - val_acc: 0.8679\n",
      "Epoch 20/30\n",
      "8000/8000 [==============================] - 76s 9ms/sample - loss: 0.2681 - acc: 0.9186 - val_loss: 0.4535 - val_acc: 0.8688\n",
      "Epoch 21/30\n",
      "8000/8000 [==============================] - 78s 10ms/sample - loss: 0.2589 - acc: 0.9215 - val_loss: 0.4518 - val_acc: 0.8690\n",
      "Epoch 22/30\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 0.2507 - acc: 0.9241 - val_loss: 0.4521 - val_acc: 0.8695\n",
      "Epoch 23/30\n",
      "8000/8000 [==============================] - 76s 10ms/sample - loss: 0.2424 - acc: 0.9265 - val_loss: 0.4512 - val_acc: 0.8709\n",
      "Epoch 24/30\n",
      "8000/8000 [==============================] - 75s 9ms/sample - loss: 0.2345 - acc: 0.9285 - val_loss: 0.4542 - val_acc: 0.8712\n",
      "Epoch 25/30\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 0.2269 - acc: 0.9309 - val_loss: 0.4551 - val_acc: 0.8714\n",
      "Epoch 26/30\n",
      "8000/8000 [==============================] - 78s 10ms/sample - loss: 0.2198 - acc: 0.9331 - val_loss: 0.4560 - val_acc: 0.8722\n",
      "Epoch 27/30\n",
      "8000/8000 [==============================] - 76s 9ms/sample - loss: 0.2127 - acc: 0.9350 - val_loss: 0.4585 - val_acc: 0.8722\n",
      "Epoch 28/30\n",
      "8000/8000 [==============================] - 76s 9ms/sample - loss: 0.2063 - acc: 0.9370 - val_loss: 0.4582 - val_acc: 0.8731\n",
      "Epoch 29/30\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 0.2002 - acc: 0.9388 - val_loss: 0.4633 - val_acc: 0.8733\n",
      "Epoch 30/30\n",
      "8000/8000 [==============================] - 75s 9ms/sample - loss: 0.1940 - acc: 0.9408 - val_loss: 0.4684 - val_acc: 0.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x273e116ba08>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data] , decoder_target_data , \n",
    "          batch_size=batch_size , \n",
    "          epochs=ephoc, \n",
    "          validation_split=0.2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_input = [ decoder_state_input_h , decoder_state_input_c ]\n",
    "\n",
    "decoder_outputs , state_h , state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_input)\n",
    "\n",
    "decoder_state = [state_h , state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( \n",
    "                    [decoder_inputs] + decoder_states_input, \n",
    "                    [decoder_outputs] + decoder_state )\n",
    "\n",
    "reverse_input_char_index = dict( (i, char) for char, i in input_token_index.items() )\n",
    "reverse_target_char_index = dict( (i, char) for char, i in target_token_index.items() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1,num_decoder_token))\n",
    "    \n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value )\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0 ,-1 , :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "            \n",
    "        taeget_seq = np.zeros((1, 1, num_decoder_token))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input Sentense: Go.\n",
      "Decoded Sentense: Attrraiverrrrrrrrrss-ttttt-ttttttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input Sentense: Hi.\n",
      "Decoded Sentense: Saluitt.. \n",
      "\n",
      "-\n",
      "Input Sentense: Hi.\n",
      "Decoded Sentense: Saluitt.. \n",
      "\n",
      "-\n",
      "Input Sentense: Run!\n",
      "Decoded Sentense: Trouiiisssrrrrrrrrrerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Run!\n",
      "Decoded Sentense: Trouiiisssrrrrrrrrrerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Who?\n",
      "Decoded Sentense: Qui llennn         ss sssssssssssssss ssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: Wow!\n",
      "Decoded Sentense: Bonnnnnnnsôttereeeeeeeeee tttsssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: Fire!\n",
      "Decoded Sentense: Attrre-virrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Help!\n",
      "Decoded Sentense: Gorrûllèrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Jump.\n",
      "Decoded Sentense: Suyye.. \n",
      "\n",
      "-\n",
      "Input Sentense: Stop!\n",
      "Decoded Sentense: Attrraviiiiiirrrrrrrerrrrrrrrrrttttttttttttttttttttdssss-eee\n",
      "-\n",
      "Input Sentense: Stop!\n",
      "Decoded Sentense: Attrraviiiiiirrrrrrrerrrrrrrrrrttttttttttttttttttttdssss-eee\n",
      "-\n",
      "Input Sentense: Stop!\n",
      "Decoded Sentense: Attrraviiiiiirrrrrrrerrrrrrrrrrttttttttttttttttttttdssss-eee\n",
      "-\n",
      "Input Sentense: Wait!\n",
      "Decoded Sentense: Attrraiverrrrrrrrrrttttttttttttttttttss-tttttttttttttitttttt\n",
      "-\n",
      "Input Sentense: Wait!\n",
      "Decoded Sentense: Attrraiverrrrrrrrrrttttttttttttttttttss-tttttttttttttitttttt\n",
      "-\n",
      "Input Sentense: Go on.\n",
      "Decoded Sentense: Vas-y yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
      "-\n",
      "Input Sentense: Go on.\n",
      "Decoded Sentense: Vas-y yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
      "-\n",
      "Input Sentense: Go on.\n",
      "Decoded Sentense: Vas-y yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
      "-\n",
      "Input Sentense: Hello!\n",
      "Decoded Sentense: Recullleeeexeeeeeeeexxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "-\n",
      "Input Sentense: Hello!\n",
      "Decoded Sentense: Recullleeeexeeeeeeeexxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "-\n",
      "Input Sentense: I see.\n",
      "Decoded Sentense: Je suvsissssssssssstttteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I try.\n",
      "Decoded Sentense: J'eis attttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input Sentense: I won!\n",
      "Decoded Sentense: J'eis adpsoussssstrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrreeeeeeee\n",
      "-\n",
      "Input Sentense: I won!\n",
      "Decoded Sentense: J'eis adpsoussssstrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrreeeeeeee\n",
      "-\n",
      "Input Sentense: I won.\n",
      "Decoded Sentense: Je suviissstraitiriiirrrrrrrtttttttteeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: Oh no!\n",
      "Decoded Sentense: Oh nonnt'eunnnnnnnnnnnnnnnnnnnnnnrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Attack!\n",
      "Decoded Sentense: Attraptrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Attack!\n",
      "Decoded Sentense: Attraptrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: Cheers!\n",
      "Decoded Sentense: À qu'u'''eclilllllllllluuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuulllll\n",
      "-\n",
      "Input Sentense: Cheers!\n",
      "Decoded Sentense: À qu'u'''eclilllllllllluuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuulllll\n",
      "-\n",
      "Input Sentense: Cheers!\n",
      "Decoded Sentense: À qu'u'''eclilllllllllluuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuulllll\n",
      "-\n",
      "Input Sentense: Cheers!\n",
      "Decoded Sentense: À qu'u'''eclilllllllllluuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuulllll\n",
      "-\n",
      "Input Sentense: Get up.\n",
      "Decoded Sentense: Sorrinnssssssssssssssssss-te---------ttttsss tttttttttnnnnnn\n",
      "-\n",
      "Input Sentense: Get up.\n",
      "Decoded Sentense: Sorrinnssssssssssssssssss-te---------ttttsss tttttttttnnnnnn\n",
      "-\n",
      "Input Sentense: Go now.\n",
      "Decoded Sentense: Vass yaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input Sentense: Go now.\n",
      "Decoded Sentense: Vass yaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input Sentense: Go now.\n",
      "Decoded Sentense: Vass yaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input Sentense: Got it!\n",
      "Decoded Sentense: Soinnnnnsssssssssssssss-st------nnrrerr--.....  nnntccootttt\n",
      "-\n",
      "Input Sentense: Got it!\n",
      "Decoded Sentense: Soinnnnnsssssssssssssss-st------nnrrerr--.....  nnntccootttt\n",
      "-\n",
      "Input Sentense: Got it?\n",
      "Decoded Sentense: Va vaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input Sentense: Got it?\n",
      "Decoded Sentense: Va vaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input Sentense: Got it?\n",
      "Decoded Sentense: Va vaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input Sentense: Hop in.\n",
      "Decoded Sentense: Goûrrrrrrrrrr  !\n",
      "\n",
      "-\n",
      "Input Sentense: Hop in.\n",
      "Decoded Sentense: Goûrrrrrrrrrr  !\n",
      "\n",
      "-\n",
      "Input Sentense: Hug me.\n",
      "Decoded Sentense: Serrz--voui.................................................\n",
      "-\n",
      "Input Sentense: Hug me.\n",
      "Decoded Sentense: Serrz--voui.................................................\n",
      "-\n",
      "Input Sentense: I fell.\n",
      "Decoded Sentense: Je suvsisssssssstreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I fell.\n",
      "Decoded Sentense: Je suvsisssssssstreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I fled.\n",
      "Decoded Sentense: Je suss svissssssssesereeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I know.\n",
      "Decoded Sentense: Je n'avauvvivvvvvvsssssseeeeeteteeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I left.\n",
      "Decoded Sentense: Je m'aidddnegennnnnnnnnnnnnnnneeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I left.\n",
      "Decoded Sentense: Je m'aidddnegennnnnnnnnnnnnnnneeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I lied.\n",
      "Decoded Sentense: J'eisa ttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input Sentense: I lost.\n",
      "Decoded Sentense: Je m'aidddnegennnnnnnnnnnnnnneeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I paid.\n",
      "Decoded Sentense: J'eis apppllaaaaudsteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input Sentense: I'm 19.\n",
      "Decoded Sentense: Je suttis ss sssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: I'm OK.\n",
      "Decoded Sentense: Je suttis ss sssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: I'm OK.\n",
      "Decoded Sentense: Je suttis ss sssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: Listen.\n",
      "Decoded Sentense: Regarrdeeeeeeerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: No way!\n",
      "Decoded Sentense: Prreadss ssssssssssssssousssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: Really?\n",
      "Decoded Sentense: Choiennnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Really?\n",
      "Decoded Sentense: Choiennnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Really?\n",
      "Decoded Sentense: Choiennnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Thanks.\n",
      "Decoded Sentense: Merrr ceheaonccccccccccttinnccnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Thanks.\n",
      "Decoded Sentense: Merrr ceheaonccccccccccttinnccnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: We try.\n",
      "Decoded Sentense: Nousssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: We won.\n",
      "Decoded Sentense: Nous sssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: We won.\n",
      "Decoded Sentense: Nous sssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: We won.\n",
      "Decoded Sentense: Nous sssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: We won.\n",
      "Decoded Sentense: Nous sssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input Sentense: Ask Tom.\n",
      "Decoded Sentense: Demmnna dis sssssssssstttotttttttnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Awesome!\n",
      "Decoded Sentense: Commnnn'e'''''''''''innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Be calm.\n",
      "Decoded Sentense: Soymiez nn nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input Sentense: Be calm.\n",
      "Decoded Sentense: Soymiez nn nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Be calm.\n",
      "Decoded Sentense: Soymiez nn nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Be cool.\n",
      "Decoded Sentense: Soymiez znnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Be fair.\n",
      "Decoded Sentense: Soyez zs-ccccunnn.n.............................ffi.........\n",
      "-\n",
      "Input Sentense: Be fair.\n",
      "Decoded Sentense: Soyez zs-ccccunnn.n.............................ffi.........\n",
      "-\n",
      "Input Sentense: Be fair.\n",
      "Decoded Sentense: Soyez zs-ccccunnn.n.............................ffi.........\n",
      "-\n",
      "Input Sentense: Be fair.\n",
      "Decoded Sentense: Soyez zs-ccccunnn.n.............................ffi.........\n",
      "-\n",
      "Input Sentense: Be fair.\n",
      "Decoded Sentense: Soyez zs-ccccunnn.n.............................ffi.........\n",
      "-\n",
      "Input Sentense: Be fair.\n",
      "Decoded Sentense: Soyez zs-ccccunnn.n.............................ffi.........\n",
      "-\n",
      "Input Sentense: Be kind.\n",
      "Decoded Sentense: Tommminnnnnennnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input Sentense: Be nice.\n",
      "Decoded Sentense: Soyezzzz-------.............................................\n",
      "-\n",
      "Input Sentense: Be nice.\n",
      "Decoded Sentense: Soyezzzz-------.............................................\n",
      "-\n",
      "Input Sentense: Be nice.\n",
      "Decoded Sentense: Soyezzzz-------.............................................\n",
      "-\n",
      "Input Sentense: Be nice.\n",
      "Decoded Sentense: Soyezzzz-------.............................................\n",
      "-\n",
      "Input Sentense: Be nice.\n",
      "Decoded Sentense: Soyezzzz-------.............................................\n",
      "-\n",
      "Input Sentense: Be nice.\n",
      "Decoded Sentense: Soyezzzz-------.............................................\n",
      "-\n",
      "Input Sentense: Beat it.\n",
      "Decoded Sentense: Oublliex      !!\n",
      "\n",
      "-\n",
      "Input Sentense: Burn it.\n",
      "Decoded Sentense: Brûûell.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_seq = decode_sequence(input_seq) \n",
    "    \n",
    "    print('-')\n",
    "    print('Input Sentense:' , input_texts[seq_index] )\n",
    "    print('Decoded Sentense:' , decoded_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
